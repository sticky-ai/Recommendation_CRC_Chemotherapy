{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "* **Data Preprocessing**\n",
    "    - Missing Data Preprocessing\n",
    "    - One-hot Encoding / Normalization\n",
    "    - Data Oversampling (Before & After Descriptive Statistics)\n",
    "\n",
    "* **Descriptive Statistics**\n",
    "    - Categorical Feature (N)\n",
    "    - Numerical Feature (Mean, SD, T-Test, $X^2$ Test) \n",
    "    \n",
    "* **Model**\n",
    "    - Machine Learning Algorithms\n",
    "    - Deep Learning Model (Reference Model)\n",
    "\n",
    "* **Evaluation**\n",
    "    - Recall, Precision, F1-Score, ROC Curve, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3319, 44)\n"
     ]
    }
   ],
   "source": [
    "df_og = pd.read_excel('./datasets/200525_EMR_V3_Priorities_only.xlsx')\n",
    "print(df_og.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3319, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = ['Operation_date', 'Last_Follow_Up_Date', 'Death_Date']\n",
    "df = df_og.drop(date, axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Missing Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 41)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Postop_Chemo_Regimen'].notnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has been dropped : ['Family_history_cancer', 'Location_of_rectal_cancer', 'Radicality', 'MSI_status', 'Recurrence_Type']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1934, 36)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drop_missing_features(df):\n",
    "    drop_features = [c for c in df.columns if df[c].isnull().sum() > 500]\n",
    "    print('Has been dropped : {}'.format(drop_features))\n",
    "    df = df.drop(drop_features, axis = 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = drop_missing_features(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549, 36)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()[:5]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical type : 5,        categorical type : 30\n"
     ]
    }
   ],
   "source": [
    "target = 'Postop_Chemo_Regimen'\n",
    "numerical = ['Age', 'BMI', 'Initial_CEA', 'Harvested_LN', 'Positive_LN']\n",
    "categorical = [nc for nc in df.columns if nc not in numerical and nc not in date and nc != target]\n",
    "\n",
    "print('numerical type : {}, \\\n",
    "       categorical type : {}'.format(len(numerical), len(categorical)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    679\n",
       "1.0    546\n",
       "6.0    124\n",
       "2.0    119\n",
       "4.0     41\n",
       "5.0     40\n",
       "Name: Postop_Chemo_Regimen, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[target].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 5-FU/LV\n",
    "2. XELODA\n",
    "3. FOLFOX\n",
    "4. XELOX\n",
    "5. FOLFIRI\n",
    "6. ERBITUX, Avastin (표적 치료제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Feature Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_target_feature(df, target_name):\n",
    "    target = df[target_name].astype(str)\n",
    "    df = df.drop([target_name], axis=1)\n",
    "    return df, target\n",
    "\n",
    "\n",
    "def numerical_preprocessing(df, numerical_cols):\n",
    "    scaler = MinMaxScaler()\n",
    "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "def categorical_preprocessing(df, categorical_cols, onehot_cols):\n",
    "    for c in categorical_cols:\n",
    "        df[c] = df[c].astype(str)\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=onehot_cols)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1549, 35) (1549,)\n"
     ]
    }
   ],
   "source": [
    "df, target = split_target_feature(df, target)\n",
    "print(df.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연속형 및 범주형 변수 전처리 (정규화 & 원-핫 인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_onehot_features = ['Sex', 'DM_history', 'Pulmonary_disease', 'Liver_disease', 'Hereditary_colorectal_tumor',\n",
    "                   'Perforation', 'Obstruction', 'Emergency', 'Early_Complication', 'Recurrence']\n",
    "\n",
    "onehot_features = [c for c in categorical if c not in not_onehot_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "X = numerical_preprocessing(df, numerical)\n",
    "X = categorical_preprocessing(df, categorical, onehot_features)\n",
    "Y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1549, 112), (1549,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1239, 112) (310, 112) (1239,) (310,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from keras.layers import Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(128, input_dim=112, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=16, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=200528)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 65.62% (3.99%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, x_train, y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics (Before Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
